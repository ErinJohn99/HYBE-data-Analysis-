{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020812f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre processing the text data for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab71ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Erin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Erin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               News   \\\n",
      "0  The shares are of high interest however are vo...   \n",
      "1  Take a bow, BTS. The K-pop phenomenon have rec...   \n",
      "2  BTS’s new single “Butter” has already broken a...   \n",
      "3  Coldplay and BTS rocket onto the Billboard Hot...   \n",
      "4  Between winning awards, commanding the stage a...   \n",
      "\n",
      "                                   Processed Article  \n",
      "0  share high interest however volatile lamed big...  \n",
      "1  take bow bts kpop phenomenon received 2020 ifp...  \n",
      "2  bts ’ new single “ butter ” already broken imp...  \n",
      "3  coldplay bts rocket onto billboard hot 100 son...  \n",
      "4  winning award commanding stage spending time c...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK data files (only need to do this once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_excel('Data for sentiment analysis.xlsx')\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to pre-process the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the words (convert them to base form)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Rejoin the words into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the pre-processing function to the \"News Article\" column\n",
    "df['Processed Article'] = df['News '].apply(preprocess_text)\n",
    "\n",
    "# Save the cleaned text back to Excel (optional)\n",
    "df.to_excel('preprocessed_file.xlsx', index=False)\n",
    "\n",
    "print(df[['News ', 'Processed Article']].head())  # Display some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing done "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
